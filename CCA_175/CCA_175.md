Tips :

Avoid typing the directory names, just copy from the questions and paste in your program. Otherwise, your output will go on different directory and you will not get credit even for the correct answer.

You should know to increase the font size of window. Ctrl+ for browser and ctrl+shift+ for terminal. I must say you will not able to differentiate dot(.) and(*) and i guarantee that you need to know how to increase font size.

You have to memorize some of the commands, configuration, compression parameters. Better to memorize those stuff which you don’t want to search in documentation as this will KILL the time.

the exam allows you to access some documentation online, namely the list at the bottom of the exam home page. Familiarize yourself with the necessary sections there (Sqoop, Spark, Flume, Python, and Scala).

I have been asked 2 sqoop, 1 hive and 6 spark questions. Sqoop questions are generally easy,command based and can be prepared in short time. Get the sqoop ready in order to get 2 questions credits very easily.

Plan :
http://arun-teaches-u-tech.blogspot.com/p/certification-preparation-plan.html

This one seems better -->
https://www.alpha-epsilon.de/cca175/2017/07/16/preparing-for-the-cloudera-exam-cca175-spark-and-hadoop-developer/ 




Sqoop :
https://hadoopbaseblog.wordpress.com/2017/03/03/sqoop-related-exam-questions-cca-175/

http://archive.cloudera.com/cdh5/cdh/5/sqoop-1.4.6-cdh5.15.0/SqoopUserGuide.html

Spark:

http://spark.apache.org/docs/2.3.0/

Docker Image :
https://medium.com/@dataakkadian/how-to-install-and-running-cloudera-docker-container-on-ubuntu-b7c77f147e03


Expand the downloaded tar.gz file. There is packaging issue with manual download, untar multiple times to get the final .tar file
Import the docker image:
    docker import cloudera-quickstart-vm-5.13.0-0-beta-docker.tar cloudera/quickstart:latest
	
	docker run --hostname=quickstart.cloudera --privileged=true -t -i -p 7180:7180 -p 80:80 -p 8888:8888 -p 7187:7187 -p 8088:8088 -p 19888:19888 cloudera/quickstart /usr/bin/docker-quickstart
	
	OR 
	
	docker run -m 4G --memory-reservation 2G --memory-swap 8G --hostname=quickstart.cloudera --privileged=true -t -i -v $(pwd):/zaid --publish-all=true -p8888 -p8088 cloudera/quickstart /usr/bin/docker-quickstart



Cloudera Manager is not started by default. To see options for starting Cloudera Manager, run the following command:

/home/cloudera/cloudera-manager

You can look up the interface to which it binds and the port number it maps to using the following command:

docker port [CONTAINER HASH] [GUEST PORT]

And to see if we are running Docker CE with the minimum configuration we use this command.

docker stats [CONTAINER ID]

you can connect to the shell later using the following command:

docker attach [CONTAINER ID]   -- same session

docker exec -it  [CONTAINER ID] /bin/bash -- differnt session
-------------------------------------------------------------------

# Sqoop

From the command line, access a MySQL on localhost via

 mysql -h localhost -u root -pcloudera

You could enter a database name at the end, but you don’t have to. Once inside, you can poke around and check the database contents:

show databases;  -- list all available databases
use retail_db;   -- switch to this database
show tables;
select * from customers limit 10;  -- query the table

//IGNORE
//Sqoop needs permissions to access the tables. You grant these permissions from MySQL like so:
//GRANT ALL PRIVILEGES ON <database_name>.* to ''@'localhost';

##Import from MySQL to HDFS

The core command here is sqoop import, along with a lot of parameters. This is an extensive example command:

sqoop import \
  --connect "jdbc:mysql://quickstart.cloudera:3306/retail_db" \
  --username root \
  --password cloudera \
  --table products \
  --compress \
  --compression-codec org.apache.hadoop.io.compress.SnappyCodec \
  --target-dir /home/cloudera/sqoop/problem1/products \
  --as-avrodatafile;

Additionally to importing a table, this command compresses the HDFS file using the snappy codec (alternatives to .SnappyCodec are BZip2Codec, GzipCodec, and DefaultCodec).

available codecs:

bzip2           .bz2            org.apache.hadoop.io.compress.BZip2Codec
default         .deflate        org.apache.hadoop.io.compress.DefaultCodec
deflate         .deflate        org.apache.hadoop.io.compress.DeflateCodec
gzip            .gz             org.apache.hadoop.io.compress.GzipCodec
lz4             .lz4            org.apache.hadoop.io.compress.Lz4Codec
snappy          .snappy         org.apache.hadoop.io.compress.SnappyCodec


It also imports the file as an Avro file (instead of the default, a text file).

Check files at 
hadoop fs -ls /home/cloudera/sqoop/problem1/products

http://quickstart.cloudera:8088/proxy/application_1568101626988_0001/

